import gradio as gr
from openai import OpenAI
import os
import tempfile
import logging
from dotenv import load_dotenv
from markitdown import MarkItDown

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¼¸å‡ºåˆ°æ§åˆ¶å°
        logging.FileHandler('pdf2quiz.log')  # è¼¸å‡ºåˆ°æ–‡ä»¶
    ]
)
logger = logging.getLogger('pdf2quiz')

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE")
# åˆªé™¤å…¨åŸŸ clientï¼Œæ”¹ç”± generate_questions å‹•æ…‹åˆå§‹åŒ–

# âœ… åˆä½µå¤šæª”æ¡ˆæ–‡å­—

def extract_text_from_files(files, llm_key=None, baseurl=None, model_name=None):
    from openai import OpenAI
    import os

    # å„ªå…ˆä½¿ç”¨ UI å‚³å…¥å€¼ï¼Œå¦å‰‡ç”¨ .envï¼Œæœ€å¾Œæ‰ç”¨é»˜èªå€¼
    api_key = llm_key if llm_key else os.getenv("OPENAI_API_KEY")
    api_base = baseurl if baseurl else os.getenv("OPENAI_API_BASE")
    model = model_name if model_name else os.getenv("OPENAI_MODEL", "gpt-4.1")
    client = OpenAI(api_key=api_key, base_url=api_base)
    
    logger.info(f"extract_text_from_files ä½¿ç”¨çš„ API è¨­å®š - Base URL: {api_base[:10] if api_base else 'None'}..., Model: {model}")

    image_exts = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp"}
    merged_text = ""
    for f in files:
        ext = os.path.splitext(f.name)[1].lower()
        filename = os.path.basename(f.name)
        logger.info(f"è™•ç†æ–‡ä»¶: {filename} (é¡å‹: {ext})")
        
        # åœ–ç‰‡æ–‡ä»¶ç›´æ¥ä½¿ç”¨ AI è™•ç†
        if ext in image_exts:
            logger.info(f"ä½¿ç”¨ AI è™•ç†åœ–ç‰‡æ–‡ä»¶: {filename}")
            md = MarkItDown(llm_client=client, llm_model=model)
            result = md.convert(f.name)
            merged_text += result.text_content + "\n"
            logger.info(f"åœ–ç‰‡æ–‡ä»¶è™•ç†å®Œæˆ: {filename}, æå–æ–‡æœ¬é•·åº¦: {len(result.text_content)}")
        # PDF æ–‡ä»¶å…ˆå˜—è©¦æ™®é€šè™•ç†ï¼Œå¦‚æœæå–ä¸åˆ°è¶³å¤ æ–‡æœ¬å†ä½¿ç”¨ AI
        elif ext.lower() == ".pdf":
            # å…ˆå˜—è©¦æ™®é€šæ–¹å¼è™•ç†
            logger.info(f"å˜—è©¦æ™®é€šæ–¹å¼è™•ç† PDF æ–‡ä»¶: {filename}")
            md = MarkItDown()
            result = md.convert(f.name)
            
            # æª¢æŸ¥æå–çš„æ–‡æœ¬æ˜¯å¦è¶³å¤ 
            text_length = len(result.text_content.strip()) if result.text_content else 0
            logger.info(f"æ™®é€šè™•ç†æå–æ–‡æœ¬é•·åº¦: {text_length}")
            
            # å¦‚æœæ–‡æœ¬å¤ªå°‘ï¼ˆå°‘æ–¼ 100 å€‹å­—ç¬¦ï¼‰ï¼Œå¯èƒ½æ˜¯æƒæç‰ˆ PDFï¼Œéœ€è¦ AI è™•ç†
            if result.text_content and text_length > 100:
                logger.info(f"æ™®é€šè™•ç†æˆåŠŸï¼Œæ–‡æœ¬è¶³å¤ : {filename}")
                merged_text += result.text_content + "\n"
            else:
                # æ–‡æœ¬å¤ªå°‘ï¼Œå¯èƒ½æ˜¯æƒæç‰ˆ PDFï¼Œä½¿ç”¨ AI è™•ç†
                logger.info(f"æ™®é€šè™•ç†æå–æ–‡æœ¬ä¸è¶³ï¼Œåˆ‡æ›åˆ° AI è™•ç†: {filename}")
                md = MarkItDown(llm_client=client, llm_model=model)
                result = md.convert(f.name)
                merged_text += result.text_content + "\n"
                logger.info(f"AI è™•ç†å®Œæˆ: {filename}, æå–æ–‡æœ¬é•·åº¦: {len(result.text_content)}")
        # å…¶ä»–æ–‡ä»¶é¡å‹ä½¿ç”¨æ™®é€šè™•ç†
        else:
            logger.info(f"ä½¿ç”¨æ™®é€šæ–¹å¼è™•ç†æ–‡ä»¶: {filename}")
            md = MarkItDown()
            result = md.convert(f.name)
            merged_text += result.text_content + "\n"
            logger.info(f"æ–‡ä»¶è™•ç†å®Œæˆ: {filename}, æå–æ–‡æœ¬é•·åº¦: {len(result.text_content)}")
    return merged_text

# âœ… ç”¢å‡ºé¡Œç›®èˆ‡ç­”æ¡ˆï¼ˆæ ¹æ“šèªè¨€èˆ‡é¡Œå‹ï¼‰

def generate_questions(files, question_types, num_questions, lang, llm_key, baseurl, model=None):
    try:
        # å„ªå…ˆä½¿ç”¨ UI å‚³å…¥å€¼ï¼Œå¦å‰‡ç”¨ .envï¼Œæœ€å¾Œæ‰ç”¨é»˜èªå€¼
        key = llm_key if llm_key else os.getenv("OPENAI_API_KEY")
        base = baseurl if baseurl else os.getenv("OPENAI_API_BASE")
        model_name = model if model else os.getenv("OPENAI_MODEL", "gpt-4.1")
        
        logger.info(f"generate_questions ä½¿ç”¨çš„ API è¨­å®š - Base URL: {base[:10] if base else 'None'}..., Model: {model_name}")
        
        # å°‡ UI å‚³å…¥çš„å€¼å‚³éçµ¦ extract_text_from_files å‡½æ•¸
        text = extract_text_from_files(files, llm_key=key, baseurl=base, model_name=model_name)
        trimmed_text = text[:200000]

        # é€™è£¡ä¸éœ€è¦å†æ¬¡è¨­ç½® key, base å’Œ model_nameï¼Œå› ç‚ºå·²ç¶“åœ¨ä¸Šé¢è¨­ç½®éäº†
        if not key or not base:
            return {"error": "âš ï¸ è«‹è¼¸å…¥ LLM key èˆ‡ baseurl"}, ""
        client = OpenAI(api_key=key, base_url=base)

        type_map = {
            "å–®é¸é¸æ“‡é¡Œ": {
                "zh-Hant": "å–®é¸é¸æ“‡é¡Œï¼ˆæ¯é¡Œå››å€‹é¸é …ï¼‰",
                "zh-Hans": "å•é€‰é€‰æ‹©é¢˜ï¼ˆæ¯é¢˜å››ä¸ªé€‰é¡¹ï¼‰",
                "en": "single choice question (4 options)",
                "ja": "å››æŠå•é¡Œ"
            },
            "å¤šé¸é¸æ“‡é¡Œ": {
                "zh-Hant": "å¤šé¸é¸æ“‡é¡Œï¼ˆæ¯é¡Œå››åˆ°äº”å€‹é¸é …ï¼‰",
                "zh-Hans": "å¤šé€‰é€‰æ‹©é¢˜ï¼ˆæ¯é¢˜å››åˆ°äº”ä¸ªé€‰é¡¹ï¼‰",
                "en": "multiple choice question (4-5 options)",
                "ja": "è¤‡æ•°é¸æŠå•é¡Œ"
            },
            "å•ç­”é¡Œ": {
                "zh-Hant": "ç°¡ç­”é¡Œ",
                "zh-Hans": "ç®€ç­”é¢˜",
                "en": "short answer",
                "ja": "çŸ­ç­”å¼å•é¡Œ"
            },
            "ç”³è«–é¡Œ": {
                "zh-Hant": "ç”³è«–é¡Œ",
                "zh-Hans": "ç”³è®ºé¢˜",
                "en": "essay question",
                "ja": "è¨˜è¿°å¼å•é¡Œ"
            }
        }

        # ä¿®æ”¹æç¤ºè©ï¼Œè¦æ±‚ LLM ç›´æ¥ç”¢å‡ºçµæ§‹åŒ–çš„é¡Œç›®å’Œç­”æ¡ˆ
        prompt_map = {
            "ç¹é«”ä¸­æ–‡": """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å‡ºé¡Œè€…ï¼Œè«‹æ ¹æ“šä»¥ä¸‹å…§å®¹ï¼Œè¨­è¨ˆ {n} é¡Œä»¥ä¸‹é¡å‹çš„é¡Œç›®ï¼š{types}ã€‚

è«‹æ³¨æ„ï¼šä½ å¿…é ˆåš´æ ¼éµå¾ªæŒ‡å®šçš„é¡Œå‹ï¼Œå¦‚æœè¦æ±‚æ˜¯ã€Œå–®é¸é¸æ“‡é¡Œã€ï¼Œå°±å¿…é ˆç”Ÿæˆå–®é¸é¡Œï¼Œæ¯é¡Œæœ‰å››å€‹é¸é …(A,B,C,D)ï¼Œè€Œä¸”åªæœ‰ä¸€å€‹æ­£ç¢ºç­”æ¡ˆã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œå¤šé¸é¸æ“‡é¡Œã€ï¼Œå°±å¿…é ˆç”Ÿæˆå¤šé¸é¡Œï¼Œæ¯é¡Œæœ‰å››åˆ°äº”å€‹é¸é …ï¼Œå¯ä»¥æœ‰å¤šå€‹æ­£ç¢ºç­”æ¡ˆã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œå•ç­”é¡Œã€ï¼Œå°±å¿…é ˆç”Ÿæˆç°¡ç­”é¡Œï¼Œéœ€è¦ç°¡çŸ­çš„æ–‡å­—å›ç­”ã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œç”³è«–é¡Œã€ï¼Œå°±å¿…é ˆç”Ÿæˆéœ€è¦è¼ƒé•·ç¯‡å¹…å›ç­”çš„é–‹æ”¾å¼å•é¡Œã€‚

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºæ¯å€‹é¡Œç›®å’Œç­”æ¡ˆï¼š

é¡Œç›®1ï¼š[é¡Œç›®å…§å®¹]
ç­”æ¡ˆ1ï¼š[ç­”æ¡ˆå…§å®¹]

é¡Œç›®2ï¼š[é¡Œç›®å…§å®¹]
ç­”æ¡ˆ2ï¼š[ç­”æ¡ˆå…§å®¹]

...ä»¥æ­¤é¡æ¨

è«‹ç¢ºä¿é¡Œè™Ÿå’Œç­”æ¡ˆè™Ÿä¸€ä¸€å°æ‡‰ï¼Œä¸è¦ä½¿ç”¨å…¶ä»–æ ¼å¼ã€‚å…§å®¹å¦‚ä¸‹ï¼š
{text}""",
            "ç°¡é«”ä¸­æ–‡": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å‡ºé¢˜è€…ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œè®¾è®¡ {n} é¢˜ä»¥ä¸‹ç±»å‹çš„é¢˜ç›®ï¼š{types}ã€‚

è¯·æ³¨æ„ï¼šä½ å¿…é¡»ä¸¥æ ¼éµå¾ªæŒ‡å®šçš„é¢˜å‹ï¼Œå¦‚æœè¦æ±‚æ˜¯ã€Œå•é€‰é€‰æ‹©é¢˜ã€ï¼Œå°±å¿…é¡»ç”Ÿæˆå•é€‰é¢˜ï¼Œæ¯é¢˜æœ‰å››ä¸ªé€‰é¡¹(A,B,C,D)ï¼Œè€Œä¸”åªæœ‰ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œå¤šé€‰é€‰æ‹©é¢˜ã€ï¼Œå°±å¿…é¡»ç”Ÿæˆå¤šé€‰é¢˜ï¼Œæ¯é¢˜æœ‰å››åˆ°äº”ä¸ªé€‰é¡¹ï¼Œå¯ä»¥æœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œé—®ç­”é¢˜ã€ï¼Œå°±å¿…é¡»ç”Ÿæˆç®€ç­”é¢˜ï¼Œéœ€è¦ç®€çŸ­çš„æ–‡å­—å›ç­”ã€‚
å¦‚æœè¦æ±‚æ˜¯ã€Œç”³è®ºé¢˜ã€ï¼Œå°±å¿…é¡»ç”Ÿæˆéœ€è¦è¾ƒé•¿ç¯‡å¹…å›ç­”çš„å¼€æ”¾å¼é—®é¢˜ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸ªé¢˜ç›®å’Œç­”æ¡ˆï¼š

é¢˜ç›®1ï¼š[é¢˜ç›®å†…å®¹]
ç­”æ¡ˆ1ï¼š[ç­”æ¡ˆå†…å®¹]

é¢˜ç›®2ï¼š[é¢˜ç›®å†…å®¹]
ç­”æ¡ˆ2ï¼š[ç­”æ¡ˆå†…å®¹]

...ä»¥æ­¤ç±»æ¨

è¯·ç¡®ä¿é¢˜å·å’Œç­”æ¡ˆå·ä¸€ä¸€å¯¹åº”ï¼Œä¸è¦ä½¿ç”¨å…¶ä»–æ ¼å¼ã€‚å†…å®¹å¦‚ä¸‹ï¼š
{text}""",
            "English": """You are a professional exam writer. Based on the following content, generate {n} questions of types: {types}.

IMPORTANT: You must strictly follow the specified question types:
- If "single choice question" is requested, create multiple choice questions with four options (A,B,C,D) and only ONE correct answer.
- If "multiple choice question" is requested, create questions with 4-5 options where MORE THAN ONE option can be correct.
- If "short answer" is requested, create questions requiring brief text responses.
- If "essay question" is requested, create open-ended questions requiring longer responses.

Please strictly follow this format for each question and answer:

Question1: [question content]
Answer1: [answer content]

Question2: [question content]
Answer2: [answer content]

...and so on

Ensure that question numbers and answer numbers correspond exactly. Do not use any other format. Content:
{text}""",
            "æ—¥æœ¬èª": """ã‚ãªãŸã¯ãƒ—ãƒ­ã®å‡ºé¡Œè€…ã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€{types}ã‚’å«ã‚€{n}å•ã®å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

é‡è¦ï¼šæŒ‡å®šã•ã‚ŒãŸå•é¡Œã‚¿ã‚¤ãƒ—ã‚’å³å®ˆã—ã¦ãã ã•ã„ï¼š
- ã€Œå››æŠå•é¡Œã€ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆã€4ã¤ã®é¸æŠè‚¢ï¼ˆA,B,C,Dï¼‰ãŒã‚ã‚Šã€æ­£è§£ãŒ1ã¤ã ã‘ã®é¸æŠå•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- ã€Œè¤‡æ•°é¸æŠå•é¡Œã€ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆã€4ã€œ5ã¤ã®é¸æŠè‚¢ãŒã‚ã‚Šã€è¤‡æ•°ã®æ­£è§£ãŒã‚ã‚‹å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- ã€ŒçŸ­ç­”å¼å•é¡Œã€ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆã€ç°¡æ½”ãªæ–‡ç« ã§ã®å›ç­”ãŒå¿…è¦ãªå•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
- ã€Œè¨˜è¿°å¼å•é¡Œã€ãŒè¦æ±‚ã•ã‚ŒãŸå ´åˆã€ã‚ˆã‚Šé•·ã„å›ç­”ãŒå¿…è¦ãªé–‹æ”¾å‹ã®å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®å½¢å¼ã§å„å•é¡Œã¨å›ç­”ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

å•é¡Œ1ï¼š[å•é¡Œå†…å®¹]
å›ç­”1ï¼š[å›ç­”å†…å®¹]

å•é¡Œ2ï¼š[å•é¡Œå†…å®¹]
å›ç­”2ï¼š[å›ç­”å†…å®¹]

...ãªã©

å•é¡Œç•ªå·ã¨å›ç­”ç•ªå·ãŒæ­£ç¢ºã«å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä»–ã®å½¢å¼ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚å†…å®¹ï¼š
{text}"""
        }

        lang_key_map = {
            "ç¹é«”ä¸­æ–‡": "zh-Hant",
            "ç°¡é«”ä¸­æ–‡": "zh-Hans",
            "English": "en",
            "æ—¥æœ¬èª": "ja"
        }

        lang_key = lang_key_map[lang]
        
        # è™•ç†å­—ä¸²å½¢å¼çš„ question_typesï¼ˆä¾†è‡ª APIï¼‰
        if isinstance(question_types, str):
            # å…ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œå†ç”¨é “è™Ÿåˆ†éš”
            qt_list = []
            for part in question_types.split(","):
                for subpart in part.split("ã€"):
                    if subpart.strip():
                        qt_list.append(subpart.strip())
            question_types = qt_list
        
        # æª¢æŸ¥æ¯å€‹é¡Œå‹æ˜¯å¦æœ‰æ•ˆ
        valid_types = list(type_map.keys())
        for t in question_types:
            if t not in valid_types:
                return {"error": f"âš ï¸ ç„¡æ•ˆçš„é¡Œå‹ï¼š{t}ã€‚æœ‰æ•ˆé¡Œå‹ç‚ºï¼š{', '.join(valid_types)}"}, ""
        
        try:
            types_str = "ã€".join([type_map[t][lang_key] for t in question_types])
            prompt = prompt_map[lang].format(n=num_questions, types=types_str, text=trimmed_text)
        except Exception as e:
            return {"error": f"âš ï¸ è™•ç†é¡Œå‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ã€‚question_types={question_types}"}, ""

        logger.info(f"ç™¼é€è«‹æ±‚åˆ° LLM æ¨¡å‹: {model_name}")
        logger.info(f"ä½¿ç”¨èªè¨€: {lang}, é¡Œå‹: {types_str}, é¡Œç›®æ•¸é‡: {num_questions}")
        logger.info(f"é¸æ“‡çš„é¡Œå‹: {question_types}")
        
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}]
        )
        content = response.choices[0].message.content
        logger.info("LLM å›æ‡‰æˆåŠŸï¼Œé–‹å§‹è§£æå›æ‡‰å…§å®¹")

        # è§£æ LLM å›å‚³çš„çµæ§‹åŒ–å…§å®¹
        import re
        
        # åˆå§‹åŒ–çµæœ
        result = {
            "questions": [],
            "answers": []
        }
        
        # æ ¹æ“šèªè¨€é¸æ“‡æ­£å‰‡è¡¨é”å¼æ¨¡å¼
        if lang == "English":
            question_pattern = r"Question(\d+):\s*(.*?)(?=\nAnswer\d+:|$)"
            answer_pattern = r"Answer(\d+):\s*(.*?)(?=\nQuestion\d+:|$)"
        elif lang == "æ—¥æœ¬èª":
            question_pattern = r"å•é¡Œ(\d+)ï¼š\s*(.*?)(?=\nå›ç­”\d+ï¼š|$)"
            answer_pattern = r"å›ç­”(\d+)ï¼š\s*(.*?)(?=\nå•é¡Œ\d+ï¼š|$)"
        else:  # ç¹é«”ä¸­æ–‡ or ç°¡é«”ä¸­æ–‡
            question_pattern = r"é¡Œç›®(\d+)ï¼š\s*(.*?)(?=\nç­”æ¡ˆ\d+ï¼š|$)"
            answer_pattern = r"ç­”æ¡ˆ(\d+)ï¼š\s*(.*?)(?=\né¡Œç›®\d+ï¼š|$)"
        
        # æå–é¡Œç›®å’Œç­”æ¡ˆ
        questions_matches = re.findall(question_pattern, content, re.DOTALL)
        answers_matches = re.findall(answer_pattern, content, re.DOTALL)
        
        # çµ„ç¹”é¡Œç›®å’Œç­”æ¡ˆ
        questions_dict = {num: text.strip() for num, text in questions_matches}
        answers_dict = {num: text.strip() for num, text in answers_matches}
        
        # ç¢ºä¿é¡Œç›®å’Œç­”æ¡ˆä¸€ä¸€å°æ‡‰
        all_numbers = sorted(set(list(questions_dict.keys()) + list(answers_dict.keys())), key=int)
        
        for num in all_numbers:
            question = questions_dict.get(num, f"é¡Œç›® {num} ç¼ºå¤±")
            answer = answers_dict.get(num, f"ç­”æ¡ˆ {num} ç¼ºå¤±")
            
            result["questions"].append({
                "number": num,
                "content": question
            })
            
            result["answers"].append({
                "number": num,
                "content": answer
            })
        
        # è¨˜éŒ„æå–çš„é¡Œç›®å’Œç­”æ¡ˆ
        if result["questions"]:
            logger.info(f"æˆåŠŸæå–é¡Œç›®å’Œç­”æ¡ˆ: {len(result['questions'])} é¡Œ")
            for q in result["questions"]:
                logger.info(f"é¡Œç›® {q['number']}: {q['content'][:50]}...")
            for a in result["answers"]:
                logger.info(f"ç­”æ¡ˆ {a['number']}: {a['content'][:50]}...")
        
        # å¦‚æœæ²’æœ‰æˆåŠŸæå–é¡Œç›®å’Œç­”æ¡ˆï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ³•
        if not result["questions"]:
            logger.warning("ä¸»è¦è§£ææ–¹æ³•å¤±æ•—ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•")
            # å‚™ç”¨æ–¹æ³•ï¼šæŒ‰è¡Œåˆ†æ
            lines = content.strip().split("\n")
            current_number = ""
            current_question = ""
            current_answer = ""
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # å˜—è©¦åŒ¹é…é¡Œç›®è¡Œ
                q_match = None
                if lang == "English":
                    q_match = re.match(r"Question\s*(\d+):\s*(.*)", line)
                elif lang == "æ—¥æœ¬èª":
                    q_match = re.match(r"å•é¡Œ\s*(\d+)ï¼š\s*(.*)", line)
                else:
                    q_match = re.match(r"é¡Œç›®\s*(\d+)ï¼š\s*(.*)", line)
                
                if q_match:
                    # ä¿å­˜å‰ä¸€å€‹é¡Œç›®å’Œç­”æ¡ˆ
                    if current_number and current_question:
                        result["questions"].append({
                            "number": current_number,
                            "content": current_question
                        })
                        result["answers"].append({
                            "number": current_number,
                            "content": current_answer
                        })
                    
                    # é–‹å§‹æ–°é¡Œç›®
                    current_number = q_match.group(1)
                    current_question = q_match.group(2)
                    current_answer = ""
                    continue
                
                # å˜—è©¦åŒ¹é…ç­”æ¡ˆè¡Œ
                a_match = None
                if lang == "English":
                    a_match = re.match(r"Answer\s*(\d+):\s*(.*)", line)
                elif lang == "æ—¥æœ¬èª":
                    a_match = re.match(r"å›ç­”\s*(\d+)ï¼š\s*(.*)", line)
                else:
                    a_match = re.match(r"ç­”æ¡ˆ\s*(\d+)ï¼š\s*(.*)", line)
                
                if a_match and a_match.group(1) == current_number:
                    current_answer = a_match.group(2)
            
            # ä¿å­˜æœ€å¾Œä¸€å€‹é¡Œç›®å’Œç­”æ¡ˆ
            if current_number and current_question:
                result["questions"].append({
                    "number": current_number,
                    "content": current_question
                })
                result["answers"].append({
                    "number": current_number,
                    "content": current_answer
                })
        
        # å¦‚æœä»ç„¶æ²’æœ‰æå–åˆ°é¡Œç›®å’Œç­”æ¡ˆï¼Œè¿”å›éŒ¯èª¤
        if not result["questions"]:
            logger.error("ç„¡æ³•è§£æ AI å›å‚³å…§å®¹ï¼Œæ‰€æœ‰è§£ææ–¹æ³•éƒ½å¤±æ•—")
            return {"error": "âš ï¸ ç„¡æ³•è§£æ AI å›å‚³å…§å®¹ï¼Œè«‹æª¢æŸ¥è¼¸å…¥å…§å®¹æˆ–ç¨å¾Œå†è©¦ã€‚"}, ""
        
        logger.info(f"é¡Œç›®ç”Ÿæˆå®Œæˆï¼Œå…± {len(result['questions'])} é¡Œ")
        
        # ç‚ºäº†å‘å¾Œå…¼å®¹ï¼ŒåŒæ™‚è¿”å›åŸå§‹æ–‡æœ¬æ ¼å¼
        questions_text = "\n\n".join([f"é¡Œç›®{q['number']}ï¼š{q['content']}" for q in result["questions"]])
        answers_text = "\n\n".join([f"ç­”æ¡ˆ{a['number']}ï¼š{a['content']}" for a in result["answers"]])
        
        return result, questions_text + "\n\n" + answers_text
    except Exception as e:
        logger.exception(f"ç”Ÿæˆé¡Œç›®æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return {"error": f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"}, ""

# âœ… åŒ¯å‡º Markdown, Quizletï¼ˆTSVï¼‰

def export_files(questions_text, answers_text):
    md_path = tempfile.NamedTemporaryFile(delete=False, suffix=".md").name
    with open(md_path, "w", encoding="utf-8") as f:
        f.write("# ğŸ“˜ é¡Œç›® Questions\n\n" + questions_text + "\n\n# âœ… è§£ç­” Answers\n\n" + answers_text)

    quizlet_path = tempfile.NamedTemporaryFile(delete=False, suffix=".tsv").name
    with open(quizlet_path, "w", encoding="utf-8") as f:
        for q, a in zip(questions_text.split("\n\n"), answers_text.split("\n\n")):
            q_clean = q.replace("\n", " ").replace("\r", " ")
            a_clean = a.replace("\n", " ").replace("\r", " ")
            f.write(f"{q_clean}\t{a_clean}\n")

    return md_path, quizlet_path

# âœ… Gradio UI

# --- FastAPI + Gradio æ•´åˆ ---
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import List, Optional
import uvicorn

def build_gradio_blocks():
    with gr.Blocks() as demo:
        gr.Markdown("# ğŸ“„ é€šç”¨ AI å‡ºé¡Œç³»çµ±ï¼ˆæ”¯æ´å¤šæª”ã€å¤šèªã€åŒ¯å‡ºæ ¼å¼ï¼‰- DAVID888 ")

        with gr.Row():
            with gr.Column():
                file_input = gr.File(
                    label="ä¸Šå‚³æ–‡ä»¶ï¼ˆå¯å¤šæª”ï¼‰",
                    file_types=[
                        ".pdf", ".ppt", ".pptx", ".doc", ".docx", ".xls", ".xlsx", ".csv",
                        ".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp",
                        ".mp3", ".wav", ".m4a", ".flac", ".ogg", ".aac", ".amr", ".wma", ".opus",
                        ".html", ".htm", ".json", ".xml", ".txt", ".md", ".rtf", ".log",
                        ".zip", ".epub"
                    ],
                    file_count="multiple"
                )
                lang = gr.Dropdown(["ç¹é«”ä¸­æ–‡", "ç°¡é«”ä¸­æ–‡", "English", "æ—¥æœ¬èª"], value="ç¹é«”ä¸­æ–‡", label="èªè¨€ Language")
                question_types = gr.CheckboxGroup(["å–®é¸é¸æ“‡é¡Œ", "å¤šé¸é¸æ“‡é¡Œ", "å•ç­”é¡Œ", "ç”³è«–é¡Œ"],
                                                  label="é¸æ“‡é¡Œå‹ï¼ˆå¯è¤‡é¸ï¼‰",
                                                  value=["å–®é¸é¸æ“‡é¡Œ"])
                num_questions = gr.Slider(1, 20, value=10, step=1, label="é¡Œç›®æ•¸é‡")
                llm_key = gr.Textbox(label="LLM Key (ä¸æœƒå„²å­˜)", type="password", placeholder="è«‹è¼¸å…¥ä½ çš„ LLM API Keyï¼Œç•™ç©ºå‰‡ä½¿ç”¨ .env è¨­å®š")
                baseurl = gr.Textbox(label="Base URL (å¦‚ https://api.groq.com/openai/v1 )", placeholder="è«‹è¼¸å…¥ API Base URLï¼Œç•™ç©ºå‰‡ä½¿ç”¨ .env è¨­å®š")
                model_box = gr.Textbox(label="Model åç¨±", placeholder="å¦‚ gpt-4.1, qwen-qwq-32b, ...ï¼Œç•™ç©ºå‰‡ä½¿ç”¨ .env è¨­å®š")
                generate_btn = gr.Button("âœï¸ é–‹å§‹å‡ºé¡Œ quiz")

            with gr.Column():
                qbox = gr.Textbox(label="ğŸ“˜ é¡Œç›® Questions", lines=15)
                abox = gr.Textbox(label="âœ… è§£ç­” Answers", lines=15)
                export_btn = gr.Button("ğŸ“¤ åŒ¯å‡º Markdown / Quizlet")
                md_out = gr.File(label="ğŸ“ Markdown æª”ä¸‹è¼‰")
                quizlet_out = gr.File(label="ğŸ“‹ Quizlet (TSV) æª”ä¸‹è¼‰")


        # åŒ…è£å‡½æ•¸ï¼Œå°‡ generate_questions çš„å›å‚³å€¼è½‰æ›ç‚º Gradio UI éœ€è¦çš„æ ¼å¼
        def generate_questions_for_gradio(files, question_types, num_questions, lang, llm_key, baseurl, model):
            result, raw_text = generate_questions(files, question_types, num_questions, lang, llm_key, baseurl, model)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
            if isinstance(result, dict) and "error" in result:
                return result["error"], ""
            
            # åˆ†å‰²åŸå§‹æ–‡æœ¬ç‚ºé¡Œç›®å’Œç­”æ¡ˆ
            parts = raw_text.split("\n\n")
            questions_part = ""
            answers_part = ""
            
            for part in parts:
                if part.startswith("é¡Œç›®") or part.startswith("Question") or part.startswith("å•é¡Œ"):
                    questions_part += part + "\n\n"
                elif part.startswith("ç­”æ¡ˆ") or part.startswith("Answer") or part.startswith("å›ç­”"):
                    answers_part += part + "\n\n"
            
            return questions_part.strip(), answers_part.strip()
        
        generate_btn.click(fn=generate_questions_for_gradio,
                           inputs=[file_input, question_types, num_questions, lang, llm_key, baseurl, model_box],
                           outputs=[qbox, abox])

        export_btn.click(fn=export_files,
                         inputs=[qbox, abox],
                         outputs=[md_out, quizlet_out])
    return demo

if __name__ == "__main__":
    demo = build_gradio_blocks()
    demo.launch()

# --- FastAPI API ä»‹é¢ ---
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import List, Optional
import uvicorn

api_app = FastAPI(title="AI å‡ºé¡Œç³»çµ± API")

@api_app.post("/api/generate")
async def api_generate(
    files: List[UploadFile] = File(...),
    question_types: List[str] = Form(...),
    num_questions: int = Form(...),
    lang: str = Form(...),
    llm_key: Optional[str] = Form(None),
    baseurl: Optional[str] = Form(None),
    model: Optional[str] = Form(None)
):
    # å°‡ UploadFile è½‰ç‚ºè‡¨æ™‚æª”æ¡ˆç‰©ä»¶ï¼Œèˆ‡ Gradio è¡Œç‚ºä¸€è‡´
    temp_files = []
    for f in files:
        temp = tempfile.NamedTemporaryFile(delete=False)
        temp.write(await f.read())
        temp.flush()
        temp_files.append(temp)
        temp.name = temp.name  # ä¿æŒä»‹é¢ä¸€è‡´

    # å‘¼å«åŸæœ¬çš„å‡ºé¡Œé‚è¼¯
    questions, answers = generate_questions(
        temp_files, question_types, num_questions, lang, llm_key, baseurl, model
    )

    # é—œé–‰è‡¨æ™‚æª”æ¡ˆ
    for temp in temp_files:
        temp.close()

    return JSONResponse({"questions": questions, "answers": answers})

# è‹¥è¦å•Ÿå‹• API ä¼ºæœå™¨ï¼Œè«‹åŸ·è¡Œï¼š
# uvicorn app:api_app --host 0.0.0.0 --port 7861
