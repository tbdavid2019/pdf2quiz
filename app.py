import gradio as gr
from openai import OpenAI
import os
import tempfile
from dotenv import load_dotenv
from markitdown import MarkItDown

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE")
# åˆªé™¤å…¨åŸŸ clientï¼Œæ”¹ç”± generate_questions å‹•æ…‹åˆå§‹åŒ–

# âœ… åˆä½µå¤šæª”æ¡ˆæ–‡å­—

def extract_text_from_files(files):
    from openai import OpenAI
    import os

    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE")
    client = OpenAI(api_key=api_key, base_url=api_base)

    image_exts = {".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp"}
    merged_text = ""
    for f in files:
        ext = os.path.splitext(f.name)[1].lower()
        if ext in image_exts:
            md = MarkItDown(llm_client=client, llm_model="gpt-4.1")
        else:
            md = MarkItDown()
        result = md.convert(f.name)
        merged_text += result.text_content + "\n"
    return merged_text

# âœ… ç”¢å‡ºé¡Œç›®èˆ‡ç­”æ¡ˆï¼ˆæ ¹æ“šèªè¨€èˆ‡é¡Œå‹ï¼‰

def generate_questions(files, question_types, num_questions, lang, llm_key, baseurl, model=None):
    try:
        text = extract_text_from_files(files)
        trimmed_text = text[:200000]

        # å„ªå…ˆä½¿ç”¨ .envï¼Œå¦å‰‡ç”¨ UI å‚³å…¥å€¼
        key = os.getenv("OPENAI_API_KEY") or llm_key
        base = os.getenv("OPENAI_API_BASE") or baseurl
        model_name = model or "gpt-4.1"
        if not key or not base:
            return {"error": "âš ï¸ è«‹è¼¸å…¥ LLM key èˆ‡ baseurl"}, ""
        client = OpenAI(api_key=key, base_url=base)

        type_map = {
            "å–®é¸é¸æ“‡é¡Œ": {
                "zh-Hant": "å–®é¸é¸æ“‡é¡Œï¼ˆæ¯é¡Œå››å€‹é¸é …ï¼‰",
                "zh-Hans": "å•é€‰é€‰æ‹©é¢˜ï¼ˆæ¯é¢˜å››ä¸ªé€‰é¡¹ï¼‰",
                "en": "single choice question (4 options)",
                "ja": "å››æŠå•é¡Œ"
            },
            "å¤šé¸é¸æ“‡é¡Œ": {
                "zh-Hant": "å¤šé¸é¸æ“‡é¡Œï¼ˆæ¯é¡Œå››åˆ°äº”å€‹é¸é …ï¼‰",
                "zh-Hans": "å¤šé€‰é€‰æ‹©é¢˜ï¼ˆæ¯é¢˜å››åˆ°äº”ä¸ªé€‰é¡¹ï¼‰",
                "en": "multiple choice question (4-5 options)",
                "ja": "è¤‡æ•°é¸æŠå•é¡Œ"
            },
            "å•ç­”é¡Œ": {
                "zh-Hant": "ç°¡ç­”é¡Œ",
                "zh-Hans": "ç®€ç­”é¢˜",
                "en": "short answer",
                "ja": "çŸ­ç­”å¼å•é¡Œ"
            },
            "ç”³è«–é¡Œ": {
                "zh-Hant": "ç”³è«–é¡Œ",
                "zh-Hans": "ç”³è®ºé¢˜",
                "en": "essay question",
                "ja": "è¨˜è¿°å¼å•é¡Œ"
            }
        }

        # ä¿®æ”¹æç¤ºè©ï¼Œè¦æ±‚ LLM ç›´æ¥ç”¢å‡ºçµæ§‹åŒ–çš„é¡Œç›®å’Œç­”æ¡ˆ
        prompt_map = {
            "ç¹é«”ä¸­æ–‡": """ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å‡ºé¡Œè€…ï¼Œè«‹æ ¹æ“šä»¥ä¸‹å…§å®¹ï¼Œè¨­è¨ˆ {n} é¡Œä»¥ä¸‹é¡å‹çš„é¡Œç›®ï¼š{types}ã€‚
è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºæ¯å€‹é¡Œç›®å’Œç­”æ¡ˆï¼š

é¡Œç›®1ï¼š[é¡Œç›®å…§å®¹]
ç­”æ¡ˆ1ï¼š[ç­”æ¡ˆå…§å®¹]

é¡Œç›®2ï¼š[é¡Œç›®å…§å®¹]
ç­”æ¡ˆ2ï¼š[ç­”æ¡ˆå…§å®¹]

...ä»¥æ­¤é¡æ¨

è«‹ç¢ºä¿é¡Œè™Ÿå’Œç­”æ¡ˆè™Ÿä¸€ä¸€å°æ‡‰ï¼Œä¸è¦ä½¿ç”¨å…¶ä»–æ ¼å¼ã€‚å…§å®¹å¦‚ä¸‹ï¼š
{text}""",
            "ç°¡é«”ä¸­æ–‡": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å‡ºé¢˜è€…ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œè®¾è®¡ {n} é¢˜ä»¥ä¸‹ç±»å‹çš„é¢˜ç›®ï¼š{types}ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºæ¯ä¸ªé¢˜ç›®å’Œç­”æ¡ˆï¼š

é¢˜ç›®1ï¼š[é¢˜ç›®å†…å®¹]
ç­”æ¡ˆ1ï¼š[ç­”æ¡ˆå†…å®¹]

é¢˜ç›®2ï¼š[é¢˜ç›®å†…å®¹]
ç­”æ¡ˆ2ï¼š[ç­”æ¡ˆå†…å®¹]

...ä»¥æ­¤ç±»æ¨

è¯·ç¡®ä¿é¢˜å·å’Œç­”æ¡ˆå·ä¸€ä¸€å¯¹åº”ï¼Œä¸è¦ä½¿ç”¨å…¶ä»–æ ¼å¼ã€‚å†…å®¹å¦‚ä¸‹ï¼š
{text}""",
            "English": """You are a professional exam writer. Based on the following content, generate {n} questions of types: {types}.
Please strictly follow this format for each question and answer:

Question1: [question content]
Answer1: [answer content]

Question2: [question content]
Answer2: [answer content]

...and so on

Ensure that question numbers and answer numbers correspond exactly. Do not use any other format. Content:
{text}""",
            "æ—¥æœ¬èª": """ã‚ãªãŸã¯ãƒ—ãƒ­ã®å‡ºé¡Œè€…ã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€{types}ã‚’å«ã‚€{n}å•ã®å•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®å½¢å¼ã§å„å•é¡Œã¨å›ç­”ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

å•é¡Œ1ï¼š[å•é¡Œå†…å®¹]
å›ç­”1ï¼š[å›ç­”å†…å®¹]

å•é¡Œ2ï¼š[å•é¡Œå†…å®¹]
å›ç­”2ï¼š[å›ç­”å†…å®¹]

...ãªã©

å•é¡Œç•ªå·ã¨å›ç­”ç•ªå·ãŒæ­£ç¢ºã«å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä»–ã®å½¢å¼ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚å†…å®¹ï¼š
{text}"""
        }

        lang_key_map = {
            "ç¹é«”ä¸­æ–‡": "zh-Hant",
            "ç°¡é«”ä¸­æ–‡": "zh-Hans",
            "English": "en",
            "æ—¥æœ¬èª": "ja"
        }

        lang_key = lang_key_map[lang]
        
        # è™•ç†å­—ä¸²å½¢å¼çš„ question_typesï¼ˆä¾†è‡ª APIï¼‰
        if isinstance(question_types, str):
            # å…ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œå†ç”¨é “è™Ÿåˆ†éš”
            qt_list = []
            for part in question_types.split(","):
                for subpart in part.split("ã€"):
                    if subpart.strip():
                        qt_list.append(subpart.strip())
            question_types = qt_list
        
        # æª¢æŸ¥æ¯å€‹é¡Œå‹æ˜¯å¦æœ‰æ•ˆ
        valid_types = list(type_map.keys())
        for t in question_types:
            if t not in valid_types:
                return {"error": f"âš ï¸ ç„¡æ•ˆçš„é¡Œå‹ï¼š{t}ã€‚æœ‰æ•ˆé¡Œå‹ç‚ºï¼š{', '.join(valid_types)}"}, ""
        
        try:
            types_str = "ã€".join([type_map[t][lang_key] for t in question_types])
            prompt = prompt_map[lang].format(n=num_questions, types=types_str, text=trimmed_text)
        except Exception as e:
            return {"error": f"âš ï¸ è™•ç†é¡Œå‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ã€‚question_types={question_types}"}, ""

        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}]
        )
        content = response.choices[0].message.content

        # è§£æ LLM å›å‚³çš„çµæ§‹åŒ–å…§å®¹
        import re
        
        # åˆå§‹åŒ–çµæœ
        result = {
            "questions": [],
            "answers": []
        }
        
        # æ ¹æ“šèªè¨€é¸æ“‡æ­£å‰‡è¡¨é”å¼æ¨¡å¼
        if lang == "English":
            question_pattern = r"Question(\d+):\s*(.*?)(?=\nAnswer\d+:|$)"
            answer_pattern = r"Answer(\d+):\s*(.*?)(?=\nQuestion\d+:|$)"
        elif lang == "æ—¥æœ¬èª":
            question_pattern = r"å•é¡Œ(\d+)ï¼š\s*(.*?)(?=\nå›ç­”\d+ï¼š|$)"
            answer_pattern = r"å›ç­”(\d+)ï¼š\s*(.*?)(?=\nå•é¡Œ\d+ï¼š|$)"
        else:  # ç¹é«”ä¸­æ–‡ or ç°¡é«”ä¸­æ–‡
            question_pattern = r"é¡Œç›®(\d+)ï¼š\s*(.*?)(?=\nç­”æ¡ˆ\d+ï¼š|$)"
            answer_pattern = r"ç­”æ¡ˆ(\d+)ï¼š\s*(.*?)(?=\né¡Œç›®\d+ï¼š|$)"
        
        # æå–é¡Œç›®å’Œç­”æ¡ˆ
        questions_matches = re.findall(question_pattern, content, re.DOTALL)
        answers_matches = re.findall(answer_pattern, content, re.DOTALL)
        
        # çµ„ç¹”é¡Œç›®å’Œç­”æ¡ˆ
        questions_dict = {num: text.strip() for num, text in questions_matches}
        answers_dict = {num: text.strip() for num, text in answers_matches}
        
        # ç¢ºä¿é¡Œç›®å’Œç­”æ¡ˆä¸€ä¸€å°æ‡‰
        all_numbers = sorted(set(list(questions_dict.keys()) + list(answers_dict.keys())), key=int)
        
        for num in all_numbers:
            question = questions_dict.get(num, f"é¡Œç›® {num} ç¼ºå¤±")
            answer = answers_dict.get(num, f"ç­”æ¡ˆ {num} ç¼ºå¤±")
            
            result["questions"].append({
                "number": num,
                "content": question
            })
            
            result["answers"].append({
                "number": num,
                "content": answer
            })
        
        # å¦‚æœæ²’æœ‰æˆåŠŸæå–é¡Œç›®å’Œç­”æ¡ˆï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ³•
        if not result["questions"]:
            # å‚™ç”¨æ–¹æ³•ï¼šæŒ‰è¡Œåˆ†æ
            lines = content.strip().split("\n")
            current_number = ""
            current_question = ""
            current_answer = ""
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                # å˜—è©¦åŒ¹é…é¡Œç›®è¡Œ
                q_match = None
                if lang == "English":
                    q_match = re.match(r"Question\s*(\d+):\s*(.*)", line)
                elif lang == "æ—¥æœ¬èª":
                    q_match = re.match(r"å•é¡Œ\s*(\d+)ï¼š\s*(.*)", line)
                else:
                    q_match = re.match(r"é¡Œç›®\s*(\d+)ï¼š\s*(.*)", line)
                
                if q_match:
                    # ä¿å­˜å‰ä¸€å€‹é¡Œç›®å’Œç­”æ¡ˆ
                    if current_number and current_question:
                        result["questions"].append({
                            "number": current_number,
                            "content": current_question
                        })
                        result["answers"].append({
                            "number": current_number,
                            "content": current_answer
                        })
                    
                    # é–‹å§‹æ–°é¡Œç›®
                    current_number = q_match.group(1)
                    current_question = q_match.group(2)
                    current_answer = ""
                    continue
                
                # å˜—è©¦åŒ¹é…ç­”æ¡ˆè¡Œ
                a_match = None
                if lang == "English":
                    a_match = re.match(r"Answer\s*(\d+):\s*(.*)", line)
                elif lang == "æ—¥æœ¬èª":
                    a_match = re.match(r"å›ç­”\s*(\d+)ï¼š\s*(.*)", line)
                else:
                    a_match = re.match(r"ç­”æ¡ˆ\s*(\d+)ï¼š\s*(.*)", line)
                
                if a_match and a_match.group(1) == current_number:
                    current_answer = a_match.group(2)
            
            # ä¿å­˜æœ€å¾Œä¸€å€‹é¡Œç›®å’Œç­”æ¡ˆ
            if current_number and current_question:
                result["questions"].append({
                    "number": current_number,
                    "content": current_question
                })
                result["answers"].append({
                    "number": current_number,
                    "content": current_answer
                })
        
        # å¦‚æœä»ç„¶æ²’æœ‰æå–åˆ°é¡Œç›®å’Œç­”æ¡ˆï¼Œè¿”å›éŒ¯èª¤
        if not result["questions"]:
            return {"error": "âš ï¸ ç„¡æ³•è§£æ AI å›å‚³å…§å®¹ï¼Œè«‹æª¢æŸ¥è¼¸å…¥å…§å®¹æˆ–ç¨å¾Œå†è©¦ã€‚"}, ""
        
        # ç‚ºäº†å‘å¾Œå…¼å®¹ï¼ŒåŒæ™‚è¿”å›åŸå§‹æ–‡æœ¬æ ¼å¼
        questions_text = "\n\n".join([f"é¡Œç›®{q['number']}ï¼š{q['content']}" for q in result["questions"]])
        answers_text = "\n\n".join([f"ç­”æ¡ˆ{a['number']}ï¼š{a['content']}" for a in result["answers"]])
        
        return result, questions_text + "\n\n" + answers_text
    except Exception as e:
        return {"error": f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"}, ""

# âœ… åŒ¯å‡º Markdown, Quizletï¼ˆTSVï¼‰

def export_files(questions_text, answers_text):
    md_path = tempfile.NamedTemporaryFile(delete=False, suffix=".md").name
    with open(md_path, "w", encoding="utf-8") as f:
        f.write("# ğŸ“˜ é¡Œç›® Questions\n\n" + questions_text + "\n\n# âœ… è§£ç­” Answers\n\n" + answers_text)

    quizlet_path = tempfile.NamedTemporaryFile(delete=False, suffix=".tsv").name
    with open(quizlet_path, "w", encoding="utf-8") as f:
        for q, a in zip(questions_text.split("\n\n"), answers_text.split("\n\n")):
            q_clean = q.replace("\n", " ").replace("\r", " ")
            a_clean = a.replace("\n", " ").replace("\r", " ")
            f.write(f"{q_clean}\t{a_clean}\n")

    return md_path, quizlet_path

# âœ… Gradio UI

# --- FastAPI + Gradio æ•´åˆ ---
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import List, Optional
import uvicorn

def build_gradio_blocks():
    with gr.Blocks() as demo:
        gr.Markdown("# ğŸ“„ é€šç”¨ AI å‡ºé¡Œç³»çµ±ï¼ˆæ”¯æ´å¤šæª”ã€å¤šèªã€åŒ¯å‡ºæ ¼å¼ï¼‰")

        with gr.Row():
            with gr.Column():
                file_input = gr.File(
                    label="ä¸Šå‚³æ–‡ä»¶ï¼ˆå¯å¤šæª”ï¼‰",
                    file_types=[
                        ".pdf", ".ppt", ".pptx", ".doc", ".docx", ".xls", ".xlsx", ".csv",
                        ".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp",
                        ".mp3", ".wav", ".m4a", ".flac", ".ogg", ".aac", ".amr", ".wma", ".opus",
                        ".html", ".htm", ".json", ".xml", ".txt", ".md", ".rtf", ".log",
                        ".zip", ".epub"
                    ],
                    file_count="multiple"
                )
                lang = gr.Dropdown(["ç¹é«”ä¸­æ–‡", "ç°¡é«”ä¸­æ–‡", "English", "æ—¥æœ¬èª"], value="ç¹é«”ä¸­æ–‡", label="èªè¨€ Language")
                question_types = gr.CheckboxGroup(["å–®é¸é¸æ“‡é¡Œ", "å¤šé¸é¸æ“‡é¡Œ", "å•ç­”é¡Œ", "ç”³è«–é¡Œ"],
                                                  label="é¸æ“‡é¡Œå‹ï¼ˆå¯è¤‡é¸ï¼‰",
                                                  value=["å–®é¸é¸æ“‡é¡Œ"])
                num_questions = gr.Slider(1, 20, value=10, step=1, label="é¡Œç›®æ•¸é‡")
                llm_key = gr.Textbox(label="LLM Key (ä¸æœƒå„²å­˜)", type="password", placeholder="è«‹è¼¸å…¥ä½ çš„ OpenAI API Key")
                baseurl = gr.Textbox(label="Base URL (å¦‚ https://api.openai.com/v1)",value="https://api.openai.com/v1", placeholder="è«‹è¼¸å…¥ API Base URL")
                model_box = gr.Textbox(label="Model åç¨±", value="gpt-4.1", placeholder="å¦‚ gpt-4.1, gpt-3.5-turbo, ...")
                generate_btn = gr.Button("âœï¸ é–‹å§‹å‡ºé¡Œ")

            with gr.Column():
                qbox = gr.Textbox(label="ğŸ“˜ é¡Œç›® Questions", lines=15)
                abox = gr.Textbox(label="âœ… è§£ç­” Answers", lines=15)
                export_btn = gr.Button("ğŸ“¤ åŒ¯å‡º Markdown / Quizlet")
                md_out = gr.File(label="ğŸ“ Markdown æª”ä¸‹è¼‰")
                quizlet_out = gr.File(label="ğŸ“‹ Quizlet (TSV) æª”ä¸‹è¼‰")


        # åŒ…è£å‡½æ•¸ï¼Œå°‡ generate_questions çš„å›å‚³å€¼è½‰æ›ç‚º Gradio UI éœ€è¦çš„æ ¼å¼
        def generate_questions_for_gradio(files, question_types, num_questions, lang, llm_key, baseurl, model):
            result, raw_text = generate_questions(files, question_types, num_questions, lang, llm_key, baseurl, model)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
            if isinstance(result, dict) and "error" in result:
                return result["error"], ""
            
            # åˆ†å‰²åŸå§‹æ–‡æœ¬ç‚ºé¡Œç›®å’Œç­”æ¡ˆ
            parts = raw_text.split("\n\n")
            questions_part = ""
            answers_part = ""
            
            for part in parts:
                if part.startswith("é¡Œç›®") or part.startswith("Question") or part.startswith("å•é¡Œ"):
                    questions_part += part + "\n\n"
                elif part.startswith("ç­”æ¡ˆ") or part.startswith("Answer") or part.startswith("å›ç­”"):
                    answers_part += part + "\n\n"
            
            return questions_part.strip(), answers_part.strip()
        
        generate_btn.click(fn=generate_questions_for_gradio,
                           inputs=[file_input, question_types, num_questions, lang, llm_key, baseurl, model_box],
                           outputs=[qbox, abox])

        export_btn.click(fn=export_files,
                         inputs=[qbox, abox],
                         outputs=[md_out, quizlet_out])
    return demo

if __name__ == "__main__":
    demo = build_gradio_blocks()
    demo.launch()

# --- FastAPI API ä»‹é¢ ---
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import List, Optional
import uvicorn

api_app = FastAPI(title="AI å‡ºé¡Œç³»çµ± API")

@api_app.post("/api/generate")
async def api_generate(
    files: List[UploadFile] = File(...),
    question_types: List[str] = Form(...),
    num_questions: int = Form(...),
    lang: str = Form(...),
    llm_key: Optional[str] = Form(None),
    baseurl: Optional[str] = Form(None),
    model: Optional[str] = Form(None)
):
    # å°‡ UploadFile è½‰ç‚ºè‡¨æ™‚æª”æ¡ˆç‰©ä»¶ï¼Œèˆ‡ Gradio è¡Œç‚ºä¸€è‡´
    temp_files = []
    for f in files:
        temp = tempfile.NamedTemporaryFile(delete=False)
        temp.write(await f.read())
        temp.flush()
        temp_files.append(temp)
        temp.name = temp.name  # ä¿æŒä»‹é¢ä¸€è‡´

    # å‘¼å«åŸæœ¬çš„å‡ºé¡Œé‚è¼¯
    questions, answers = generate_questions(
        temp_files, question_types, num_questions, lang, llm_key, baseurl, model
    )

    # é—œé–‰è‡¨æ™‚æª”æ¡ˆ
    for temp in temp_files:
        temp.close()

    return JSONResponse({"questions": questions, "answers": answers})

# è‹¥è¦å•Ÿå‹• API ä¼ºæœå™¨ï¼Œè«‹åŸ·è¡Œï¼š
# uvicorn app:api_app --host 0.0.0.0 --port 7861
